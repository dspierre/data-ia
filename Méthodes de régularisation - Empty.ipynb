{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Méthode de Régularisation : Lasso / Ridge / ElasticNet\n",
    "\n",
    "\n",
    "Dans le domaine des mathématiques et des statistiques, et plus particulièrement dans le domaine de l'apprentissage automatique, la régularisation fait référence à un processus consistant à **ajouter de l'information à un problème pour éviter le surapprentissage. Cette information prend généralement la forme d'une pénalité envers la complexité du modèle.** D'un point de vue bayésien, l'utilisation de la régularisation revient à imposer une distribution a priori sur les paramètres du modèle. \n",
    "\n",
    "## Consigne du jour\n",
    "\n",
    "\n",
    "### Objectifs \n",
    "Comprendre ces trois approches en les appliquant sur un cas pratique : le pricing d'un appartement ! \n",
    "\n",
    "### Livrables\n",
    "Vous avez 2 livrables à m'envoyer **pour le vendredi 19 juin 2019 23h59** : \n",
    "- Ce notebook complété avec les commentaires en conséquence (Sujet / Verbe / Complément)\n",
    "- Un résumé de veille  sur les méthodes de régularisation Ridge, Lasso et ElasticNet. Les prises de notes ne sont pas valables. Vous pouvez vous inspirer de votre atelier Dataiku afin de créer un petit article synthétique. Je n'attends pas de code Python sur ce résumé.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Importer vos librairies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "2312a211-8ef3-9d54-b2a1-493b7465e103",
    "_uuid": "4590abe3e245e740e25a991108cc6a5337597ade"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_mklinit' from partially initialized module 'numpy' (most likely due to a circular import) (C:\\Users\\pierremarie\\Anaconda3\\lib\\site-packages\\numpy\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-1f28331bd362>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;31m# Allow distributors to run custom init code\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_distributor_init\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mRTLD_for_MKL\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_mklinit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mRTLD_for_MKL\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_mklinit' from partially initialized module 'numpy' (most likely due to a circular import) (C:\\Users\\pierremarie\\Anaconda3\\lib\\site-packages\\numpy\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\") #white background style for seaborn plots\n",
    "sns.set(style=\"whitegrid\", color_codes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Importer les données boston depuis scikitlearn et afficher les dimensions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston_data = pd.DataFrame(load_boston().data,columns=load_boston().feature_names)\n",
    "boston_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Comment sont stockées vos donnnées?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Transformez vos variables explicatives en en dataframe et récupérer la target appelée `MEDV`. Vous trouverez ci-bas le détail des features.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(load_boston().data,columns=load_boston().feature_names) \n",
    "X = boston_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### data: contains the information for various houses\n",
    "##### target: prices of the house\n",
    "##### feature_names: names of the features\n",
    "##### DESCR: describes the dataset\n",
    "\n",
    "###### CRIM: Per capita crime rate by town\n",
    "##### ZN: Proportion of residential land zoned for lots over 25,000 sq. ft\n",
    "##### INDUS: Proportion of non-retail business acres per town\n",
    "##### CHAS: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)  \n",
    "##### NOX: Nitric oxide concentration (parts per 10 million)\n",
    "##### RM: Average number of rooms per dwelling\n",
    "##### AGE: Proportion of owner-occupied units built prior to 1940\n",
    "##### DIS: Weighted distances to five Boston employment centers\n",
    "##### RAD: Index of accessibility to radial highways \n",
    "##### TAX: Full-value property tax rate per $10,000$\n",
    "\n",
    "##### PTRATIO: Pupil-teacher ratio by town\n",
    "##### B: 1000(Bk — 0.63)², where Bk is the proportion of [people of African American descent] by town\n",
    "##### LSTAT: Percentage of lower status of the population\n",
    "##### MEDV: Median value of owner-occupied homes in $1000s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Missing Values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Analyser la distibution de la target et analyser la corrélation des features.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(boston_data['RM'], kde=False, rug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fg, ax = plt.subplots(figsize=(10, 10))\n",
    "plt.title('Correlation entre variables')\n",
    "sns.heatmap(boston_data.corr(),linewidths=0.25,vmax=1.0, square=True, cmap=\"YlGnBu\", linecolor='black', annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Analyser les relations entre la target et les variables `LSTAT` et `RM`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(load_boston().data,columns=load_boston().feature_names) \n",
    "df['MEDV']=Y.values \n",
    "sns.jointplot(x='LSTAT',y=df['MEDV'],data = boston_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(load_boston().data,columns=load_boston().feature_names) \n",
    "df['MEDV']=Y.values \n",
    "sns.jointplot(x='RM',y=df['MEDV'],data = boston_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. Les variables catégorielles sont mal traitées. Corriger cela.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(load_boston().DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZN = pd. get_dummies(X.ZN)\n",
    "ZN.columns = ['ZN{}'.format(j) for j in X.ZN.unique()]\n",
    "CHAS = pd. get_dummies(X.CHAS)\n",
    "CHAS.columns = ['CHAS{}'.format(j) for j in X.CHAS.unique()]\n",
    "RAD = pd. get_dummies(X.RAD)\n",
    "RAD.columns = ['RAD{}'.format(j) for j in X.RAD.unique()]\n",
    "X = pd.concat([X,ZN,CHAS,RAD],1)\n",
    "X.drop('ZN',1).drop('CHAS',1).drop('RAD',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(load_boston().data,columns=load_boston().feature_names)\n",
    "X.CHAS = X.CHAS.astype('category')\n",
    "RAD = pd.get_dummies(X.RAD)\n",
    "RAD.columns = ['RAD_{}'.format(j) for j in X.RAD.unique()]\n",
    "X = pd.concat([X,RAD],1)\n",
    "del X['RAD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. Train Test Split avec `random_state = 42`. Afficher les dimensions des objets obtenus.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train)\n",
    "print(X_test)\n",
    "print(y_train)\n",
    "print(y_test)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Régression linéaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. A des fins de comparaions, modéliser un premier modèle de régression linéaire avec toutes les variables et évaluer les performances du modèle.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state=5)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmodellineaire = LinearRegression()\n",
    "lmodellineaire.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluation du training set\n",
    "from sklearn.metrics import r2_score\n",
    "y_train_predict = lmodellineaire.predict(X_train)\n",
    "rmse = (np.sqrt(mean_squared_error(Y_train, y_train_predict)))\n",
    "r2_train = r2_score(Y_train, y_train_predict)\n",
    " \n",
    "print('La performance du modèle sur la base dapprentissage')\n",
    "print('--------------------------------------')\n",
    "print('Lerreur quadratique moyenne est {}'.format(rmse))\n",
    "print('le score R2 est {}'.format(r2))\n",
    "print('\\n')\n",
    "rmse_train = format(rmse.round(2))\n",
    "r2_train = format(r2_train.round(2))\n",
    "\n",
    "# model evaluation for testing set\n",
    "y_test_predict = lmodellineaire.predict(X_test)\n",
    "rmse = (np.sqrt(mean_squared_error(Y_test, y_test_predict)))\n",
    "r2_test = r2_score(Y_test, y_test_predict)\n",
    " \n",
    "print('')\n",
    "print('--------------------------------------')\n",
    "print(' {}'.format(rmse))\n",
    "print('le score R2 est {}'.format(r2))\n",
    "rmse_test = format(rmse.round(2))\n",
    "r2_test = format(r2_test.round(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Régression Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Rappelez le principe de la méthode et la pénalisation Ridge.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajouter une contrainte sur les coefficients lors de la modélisation pour maîtriser\n",
    "l’amplitude de leurs valeurs (« pour éviter qu’elles partent dans tous les sens »)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Quels sont les paramètres à faire varier?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "λ (λ ≥ 0) est un paramètre (coefficient\n",
    "de pénalité) qui permet de contrôler\n",
    "l’impact de la pénalité : à fixer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Instancier un modèle `Ridge` en faisant varier le paramètre `alpha` avec une `GridSearchCV` (5k-fold) et lala liste ci dessous.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "alpha_ridge = [1e-15, 1e-10, 1e-8, 1e-6, 1e-4, 1e-3, 1e-2, 1e-1, 1, 5, 10, 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Evaluer votre modèle. Afficher le meilleur paramètre et le meilleur score obtenu.**\n",
    "\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_ridge = [1e-15, 1e-10, 1e-8, 1e-6, 1e-4, 1e-3, 1e-2, 1e-1, 1, 5, 10, 20]\n",
    "print(alpha_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ridge=Ridge()\n",
    "paremeter={'alpha':alpha_ridge}\n",
    "ridge_regression=GridSearchCV(ridge,parameters,cv=5)\n",
    "ridge_regression=ridge_regression.fit(X_train, Y_train)\n",
    "print(ridge_regression.best_params_)\n",
    "print(ridge_regression.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Régression Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Rappelez le principe de la méthode et la pénalisation Lasso.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Quels sont les paramètres à faire varier?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c'est le paremetre  alpha que l'on doit faire varier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Instancier un modèle `Lasso` en faisant varier le paramètre `alpha` avec une `GridSearchCV` (5k-fold) et lala liste ci dessous.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "alpha_lasso = [1e-15, 1e-10, 1e-8, 1e-6, 1e-4, 1e-3, 1e-2, 1e-1, 1, 5, 10, 20]\n",
    "#lasso=Lasso\n",
    "paremeter={'alpha':alpha_lasso}\n",
    "lasso_regression=GridSearchCV(ElasticNet(),parameters,cv=5)\n",
    "lasso_regression=lasso_regression.fit(X_train, Y_train)\n",
    "print(lasso_regression.best_params_)\n",
    "print(lasso_regression.best_score_)\n",
    "print(np.sqrt(mean_squared_error(y_train,pred_train_lasso)))\n",
    "print(r2_score(y_train,pred_train_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_regressions.core(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sqrt(mean_squared_error(y_train,pred_train_lasso)))\n",
    "print(r2_score(y_train, pred_train_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_lasso= model_lasso.predict(X_test)\n",
    "print(np.sqrt(mean_squared_error(y_test,pred_test_lasso))) \n",
    "print(r2_score(y_test, pred_test_lasso))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Evaluer votre modèle en utilisant le paramètre `scoring` adéquat et afficher le meilleur paramètre et le meilleur score obtenu.**\n",
    "\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V. Elasticnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Rappelez le principe de la méthode et la pénalisation ElasticNet.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Quels sont les paramètres à faire varier?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Instancier un modèle `ElasticNet` en faisant varier le paramètre `alpha` avec une `GridSearchCV` (5k-fold) et lala liste ci dessous.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_elasticnet= [1e-15, 1e-10, 1e-8, 1e-6, 1e-4, 1e-3, 1e-2, 1e-1, 1, 5, 10, 20]\n",
    "paremeter={'alpha':alpha_elasticnet}\n",
    "elasticnet_regression=GridSearchCV(ElasticNet(),parameters,cv=5)\n",
    "elasticnet_regression=lasso_regression.fit(X_train, Y_train)\n",
    "print(elasticnet_regression.best_params_)\n",
    "print(elasticnet_regression.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Evaluer votre modèle en utilisant le paramètre `scoring` adéquat et afficher le meilleur paramètre et le meilleur score obtenu.**\n",
    "\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(elasticnet_regression.best_params_)\n",
    "print(elasticnet_regression.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VI. Résultats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regrouper vos résultats dans un dataframe et interpréter.**\n",
    "\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models = {'Linear Regression' : ['None','None',rmse_train,r2_train,rmse_test,r2_test],\n",
    "            'Ridge' : [ridge_regression.bestparams,ridge_regression.bestscore,rmse_ridge1,r2ridge1,rmse_ridge2,r2ridge2],\n",
    "            'Lasso' : [lasso_regression.bestparams,lasso_regression.bestscore,rmse_lasso1,r2lasso1,rmse_lasso2,r2lasso2],\n",
    "            'ElasticNet':[elasticnet_regression.bestparams,elasticnet_regression.bestscore,rmse_elnet1,r2elnet1,rmse_elnet2,r2elnet2]}\n",
    "df_res=pd.DataFrame(df_models,index=['best_params','best_score','RMSE1','R2_1','RMSE2','R2_2'])\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(Res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 0,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
